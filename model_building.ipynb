{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset, DataLoader, random_split, ConcatDataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms, models\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Split\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)), # resize to 300x300 pixels \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # ImageNet normalization\n",
    "])\n",
    "\n",
    "# Dataset \n",
    "data_dir = '/content/drive/My Drive/capstone' # directory of the image dataset within Google Drive classified into the folders 'good' and 'bad'\n",
    "dataset = ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "print(f\"Class mapping: {dataset.class_to_idx}\")  # 'good' -> 1, 'bad' -> 0\n",
    "\n",
    "# Seed\n",
    "seed = 42 #start seed to replicate results\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "# Original and Augmented Datasets indices\n",
    "orig_indices = []\n",
    "aug_indices = []\n",
    "\n",
    "for idx, (path, _) in enumerate(dataset.samples):\n",
    "    if '.aug' in path:\n",
    "        aug_indices.append(idx)\n",
    "    else:\n",
    "        orig_indices.append(idx)\n",
    "\n",
    "original_dataset = Subset(dataset, orig_indices)\n",
    "\n",
    "# Split Original Dataset into 70/15/15\n",
    "total_orig = len(original_dataset)\n",
    "train_size = int(0.7 * total_orig)\n",
    "val_size = int(0.15 * total_orig)\n",
    "test_size = total_orig - train_size - val_size\n",
    "\n",
    "train_orig_dataset, val_dataset, test_dataset = random_split(original_dataset, [train_size, val_size, test_size], generator=generator)\n",
    "\n",
    "# Get image base name without augmentation suffix or file extension\n",
    "def get_image_id(path):    \n",
    "    basename = os.path.basename(path)    \n",
    "    name = basename.split('.jpg') # split by '.jpg' first    \n",
    "    base_id = name[0].split('.aug') # split by '.aug' afterward\n",
    "    return base_id[0]\n",
    "\n",
    "# Validation and Test Sets indices\n",
    "val_test_image_ids = set()\n",
    "for subset in [val_dataset, test_dataset]:\n",
    "    for idx in subset.indices:\n",
    "        orig_idx = orig_indices[idx]\n",
    "        path = dataset.samples[orig_idx][0]\n",
    "        image_id = get_image_id(path)\n",
    "        val_test_image_ids.add(image_id)\n",
    "\n",
    "# Filter Augmented Dataset to include only augmented images corresponding to the test set\n",
    "filtered_aug_indices = []\n",
    "for aug_idx in aug_indices:\n",
    "    path = dataset.samples[aug_idx][0]\n",
    "    image_id = get_image_id(path)\n",
    "    if image_id not in val_test_image_ids:\n",
    "        filtered_aug_indices.append(aug_idx)\n",
    "\n",
    "filt_aug_dataset = Subset(dataset, filtered_aug_indices)\n",
    "\n",
    "# Final Training Set\n",
    "train_dataset = ConcatDataset([train_orig_dataset, filt_aug_dataset])\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}, Test size: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save split information into dataframes\n",
    "\n",
    "# Get base dataset and indices from subset\n",
    "def get_base_dataset(dataset):\n",
    "    while isinstance(dataset, Subset):\n",
    "        indices = [dataset.indices[i] for i in indices]\n",
    "        dataset = dataset.dataset\n",
    "    return dataset, indices\n",
    "\n",
    "# Get subset filenames and labels\n",
    "def get_subset_info(subset):\n",
    "    # Get the base dataset and effective indices\n",
    "    base_dataset, indices = get_base_dataset(subset)\n",
    "\n",
    "    # Get full paths and extract just the filenames\n",
    "    full_paths = [base_dataset.imgs[i][0] for i in indices]\n",
    "    filenames = [os.path.basename(path) for path in full_paths]\n",
    "\n",
    "    # Get labels and class names\n",
    "    labels = [base_dataset.targets[i] for i in indices]\n",
    "    class_names = base_dataset.classes\n",
    "\n",
    "    # Convert numeric labels to class names\n",
    "    label_names = [class_names[label] for label in labels]\n",
    "\n",
    "    return filenames, labels, label_names\n",
    "\n",
    "train_files, train_labels, train_classes = get_subset_info(train_orig_dataset)\n",
    "val_files, val_labels, val_classes = get_subset_info(val_dataset)\n",
    "test_files, test_labels, test_classes = get_subset_info(test_dataset)\n",
    "train_aug_files, train_aug_labels, train_aug_classes = get_subset_info(filt_aug_dataset)\n",
    "\n",
    "train_df = pd.DataFrame({'filename': train_files, 'class': train_classes, 'label': train_labels})\n",
    "val_df = pd.DataFrame({'filename': val_files, 'class': val_classes, 'label': val_labels})\n",
    "test_df = pd.DataFrame({'filename': test_files, 'class': test_classes, 'label': test_labels})\n",
    "train_aug_df = pd.DataFrame({'filename': train_aug_files, 'class': train_aug_classes, 'label': train_aug_labels})\n",
    "\n",
    "output_dir = data_dir # root path for saving csv files\n",
    "\n",
    "# Full paths for csv files\n",
    "train_csv_path = os.path.join(output_dir, 'train_set.csv')\n",
    "val_csv_path = os.path.join(output_dir, 'val_set.csv')\n",
    "test_csv_path = os.path.join(output_dir, 'test_set.csv')\n",
    "train_aug_csv_path = os.path.join(output_dir, 'train_aug_set.csv')\n",
    "\n",
    "train_df.to_csv(train_csv_path, index=False)\n",
    "val_df.to_csv(val_csv_path, index=False)\n",
    "test_df.to_csv(test_csv_path, index=False)\n",
    "train_aug_df.to_csv(train_aug_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "\n",
    "# Use GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# EfficientNet-B3 model\n",
    "model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Linear(num_features, 2)\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Unfreeze the last few layers\n",
    "for name, param in model.named_parameters():\n",
    "    if \"features.6\" in name or \"classifier\" in name:  # EfficientNet last block and classifier\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "start_epoch = 0\n",
    "num_epochs = 30\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-5)\n",
    "\n",
    "# Class weights for train set\n",
    "train_df_tot = pd.concat([train_df,train_aug_df])\n",
    "all_labels = [row['label'] for _, row in train_df_tot.iterrows()]\n",
    "classes = np.unique(all_labels)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=all_labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping_patience = 8\n",
    "best_val_loss = float('inf')\n",
    "no_improvement = 0\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint_path = data_dir + '/checkpoint.pth'\n",
    "\n",
    "# Model summary\n",
    "summary(model, input_size=(3, 300, 300))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    report = classification_report(all_labels, all_preds, target_names=['Bad', 'Good'], digits=4)\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    # Save checkpoint and check early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        no_improvement = 0\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': avg_val_loss,\n",
    "        }, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1}\")\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "        if no_improvement >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model checkpoint\n",
    "\n",
    "# Use GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# EfficientNet-B3 model\n",
    "model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Linear(num_features, 2)\n",
    ")\n",
    "\n",
    "data_dir = '/content/drive/My Drive/capstone'\n",
    "checkpoint_path = data_dir + '/checkpoint.pth'\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Unfreeze the last few layers\n",
    "for name, param in model.named_parameters():\n",
    "    if \"features.6\" in name or \"classifier\" in name:  # EfficientNet last block and classifier\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 30\n",
    "start_epoch = checkpoint['epoch'] + 1\n",
    "best_val_loss = checkpoint['val_loss']\n",
    "\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-5)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# Class weights for train set\n",
    "train_df_tot = pd.concat([train_df,train_aug_df])\n",
    "all_labels = [row['label'] for _, row in train_df_tot.iterrows()]\n",
    "classes = np.unique(all_labels)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=all_labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping_patience = 8\n",
    "no_improvement = 0\n",
    "\n",
    "# checkpoint_path = data_dir + '/checkpoint2.pth' # new checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "features = []\n",
    "misclassified_indices = []\n",
    "\n",
    "feature_extractor_model = copy.deepcopy(model)\n",
    "feature_extractor_model.classifier = torch.nn.Identity()  # remove classifier for feature extraction\n",
    "feature_extractor_model.eval()\n",
    "model.eval()\n",
    "\n",
    "threshold = 0.7\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images) #classification\n",
    "        extracted_features = feature_extractor_model(images)\n",
    "        features.append(extracted_features.cpu().numpy())\n",
    "\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        prob = probabilities[:, 1]\n",
    "        predicted = (prob >= threshold).int()\n",
    "\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        pred_labels.extend(predicted.cpu().numpy())\n",
    "\n",
    "        batch_misclassified = (predicted != labels).cpu().numpy()\n",
    "        misclassified_indices.extend(np.where(batch_misclassified)[0] + batch_idx * test_loader.batch_size)\n",
    "\n",
    "features = np.vstack(features)\n",
    "true_labels = np.array(true_labels)\n",
    "pred_labels = np.array(pred_labels)\n",
    "\n",
    "test_df['prediction'] = pred_labels\n",
    "test_csv_path = data_dir + '/test_results.csv'\n",
    "test_df.to_csv(test_csv_path, index=False)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Bad', 'Good'], yticklabels=['Bad', 'Good'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(true_labels, pred_labels, target_names=['Bad', 'Good'], digits=4)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# t-SNE\n",
    "embedded_features = TSNE(n_components=2, perplexity=30, random_state=42).fit_transform(features)\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(embedded_features[:, 0], embedded_features[:, 1], c=true_labels, cmap='RdYlGn', alpha=0.7)\n",
    "plt.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "plt.scatter(embedded_features[misclassified_indices, 0], embedded_features[misclassified_indices, 1], c='black', marker='x', label='Misclassified', s=60)\n",
    "\n",
    "plt.title(\"t-SNE Visualization of Image Features\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
